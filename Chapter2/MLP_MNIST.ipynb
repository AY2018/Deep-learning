{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d975189-8d95-48fc-b2a5-e048c9f40389",
   "metadata": {},
   "source": [
    "# MNIST : RdN - MLP\n",
    "\n",
    "Plusieur étapes à suivre pour entrainer un modèle : \n",
    "1. Récupérer les données (divisées en deux ensembles : entraînement + test)\n",
    "2. Les préparer pour qu'elles soient adaptées au modèle\n",
    "3. Construction du modèle (Les couches + compilation)\n",
    "4. Entraînement du modèle\n",
    "5. Vérification du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3dade0-ec52-4d78-992c-59790fad947a",
   "metadata": {},
   "source": [
    "#### Étape 1 : récupérer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee15273-7e29-4a38-b12a-2d13490eda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d211d-ab97-4aa0-bdd3-79739eba8080",
   "metadata": {},
   "source": [
    "#### Étape 2 : préparer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb7ed53-1fbf-4691-bdc6-5c09ef1a27dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On convertit les 6000 images en Scalaires (1D) \n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# On code de manière catégorielle les labels. \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f36fa-e835-4b19-b808-c23ff27e049f",
   "metadata": {},
   "source": [
    "**One-hot encoding** : Dernière layer : activation='softmax' => elle s'attend donc à un input du type [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] = 4. D'où la convertion des labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5dc31-ad41-4a55-8aaf-1323905ab2d9",
   "metadata": {},
   "source": [
    "#### Étape 3 : Construction du modèle MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a96a4-65fc-40c7-9f55-6b8338091f8f",
   "metadata": {},
   "source": [
    "Modèle MLP = modèle séquenciel avec des couches intermédiaires denses (chaque neuronne est connecté à tout les neuronnes des couches avant et après). \n",
    "\n",
    "Limitations = \n",
    "- tendance à surajuster les données (overfitting à voir au Chap3), en particulier lorsque le réseau est très profond ou que le nombre de données d'entraînement est limité. \n",
    "- moins efficace pour traiter des données ayant une structure spatiale ou temporelle, comme les images ou les séquences,\n",
    "\n",
    "Pourquoi moins efficace pour traiter des données spatiales (Images)? \n",
    "- **Absence de prise en compte de la localité spatiale ou temporelle** : Dans un MLP, chaque neurone d'une couche est connecté à tous les neurones de la couche précédente, et il traite l'information de manière globale plutôt que locale. Cela signifie qu'un MLP ne prend pas naturellement en compte la proximité ou l'ordre des pixels dans une image, ou des mots/éléments dans une séquence. Par exemple, dans le cas des images, le MLP ne reconnaîtra pas facilement les patterns ou les textures locales, qui sont cruciaux pour la compréhension visuelle.\n",
    "- **Complexité et sur-paramétrisation** : Pour traiter des images ou des séquences avec un MLP, chaque pixel ou élément de la séquence doit être connecté à plusieurs neurones, ce qui peut rapidement augmenter le nombre de paramètres du modèle. Cela rend le réseau complexe et susceptible de surajuster, surtout lorsque la quantité de données d'entraînement est limitée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558e8d40-3a53-4f71-bbf0-9fc805791687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "network = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6aa1a-7410-4164-8cd9-d96054d44cb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pour info \n",
    "\n",
    "Fonction d'activation = un neuronne reçoit la somme de chaque valeur des neuronnes de la couche précédentes multipliée par son poids associé. On ajoute ensuite le biais du neuronne à cette somme. Cette valeur passe ensuite par une fonction qui va la transformer en une autre valeur qui sera ensuite passée au(x) neuronne(s) de la couche suivante. Cette fonction d'activation permet de ne pas avoir un réseau linéaire. \n",
    "\n",
    "Loss function = fonction de perte, permet de comparer la prédiction obtenue avec la bonne étiquette. \n",
    "\n",
    "Optimizer = Va ajuster les poids en fonction de l'output de la fonction de perte. \n",
    "\n",
    "**ps : Il existe plusieurs types de fonctions d'activations, de perte et d'optimiseurs. Il faut savoir choisir la bonne fonction pour le modèle en question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914cd9c-f6d7-4952-a1eb-889df4fb7bda",
   "metadata": {},
   "source": [
    "#### Étape 4 : Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99942798-79eb-4306-a3f2-3a6104660397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2587 - accuracy: 0.9253\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0494 - accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0366 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a13afe50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9614ef05-3fff-4d6e-86c8-bb993901715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On observe que la précision s'améliore d'epoch en epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10641edb-ca94-4800-bbfa-9098b943323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 566us/step - loss: 0.0699 - accuracy: 0.9800\n",
      "0.06992277503013611 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = network.evaluate(test_images, test_labels)\n",
    "print(val_loss, val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras Env",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
